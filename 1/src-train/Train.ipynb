{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ODTmTXgqRlTf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18690,
     "status": "ok",
     "timestamp": 1696862599658,
     "user": {
      "displayName": "Антон Бабкин",
      "userId": "11833288714987979986"
     },
     "user_tz": -180
    },
    "id": "ODTmTXgqRlTf",
    "outputId": "2f8d1938-b22a-4e50-88a5-be9068a9fd68"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.31.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (3.12.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.16.4)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (1.25.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (2023.6.3)\n",
      "Requirement already satisfied: requests in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (2.28.2)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.3.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (3.0.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (2022.12.7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: pytorch-lightning 1.5.4 has a non-standard dependency specifier torch>=1.7.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pytorch-lightning or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef31bc00",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3505,
     "status": "ok",
     "timestamp": 1696862886926,
     "user": {
      "displayName": "Антон Бабкин",
      "userId": "11833288714987979986"
     },
     "user_tz": -180
    },
    "id": "ef31bc00",
    "outputId": "8c7ba1e3-f285-4bfe-e844-5e155833d9fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import transformers\n",
    "from transformers import AutoModel, BertTokenizer#, BertForSequenceClassification\n",
    "\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "197dbaa7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 549,
     "status": "ok",
     "timestamp": 1696863071910,
     "user": {
      "displayName": "Антон Бабкин",
      "userId": "11833288714987979986"
     },
     "user_tz": -180
    },
    "id": "197dbaa7",
    "outputId": "9e0714ad-f28d-40c3-eb9b-6ac9e6ff9839"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amount 22 97\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('L.csv' ,delimiter=';', encoding='cp1251')\n",
    "\n",
    "df['Target'] = df['Group'] #+'/'+ df['Cat']\n",
    "\n",
    "\n",
    "# df= df[:50]\n",
    "\n",
    "\n",
    "\n",
    "#this needed for one hot encoding\n",
    "amount_of_classes = len(df['Target'].unique())\n",
    "\n",
    "\n",
    "encoder = sklearn.preprocessing.LabelBinarizer()\n",
    "y = encoder.fit_transform(df['Target'])\n",
    "\n",
    "#print(encoder.inverse_transform(y))\n",
    "y = pd.DataFrame(y)\n",
    "# df = pd.concat([df, y], axis=1)\n",
    "columns_to_convert = [int(i) for i in range(amount_of_classes)]\n",
    "\n",
    "\n",
    "df['Target_2'] = df['Cat'] \n",
    "amount_of_classes_2 = len(df['Target_2'].unique())\n",
    "encoder_2 = sklearn.preprocessing.LabelBinarizer()\n",
    "y_2 = encoder_2.fit_transform(df['Target_2'])\n",
    "y_2 = pd.DataFrame(y_2, columns=[str(i)+'_1' for i in range(amount_of_classes_2)])\n",
    "df = pd.concat([df, y, y_2], axis=1)\n",
    "columns_to_convert_2 = [str(i)+'_1' for i in range(amount_of_classes_2)]\n",
    "# print(df[columns_to_convert_2[0]])\n",
    "\n",
    "print('amount', amount_of_classes, amount_of_classes_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb78ec2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edf0aa3f",
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1696863071911,
     "user": {
      "displayName": "Антон Бабкин",
      "userId": "11833288714987979986"
     },
     "user_tz": -180
    },
    "id": "edf0aa3f"
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "train, val = train_test_split(train, test_size=0.25, random_state=42)\n",
    "\n",
    "\n",
    "train_x = train['Desc']\n",
    "train_y = train[columns_to_convert+columns_to_convert_2].to_numpy()\n",
    "# train_y_2 = train[columns_to_convert_2].to_numpy()\n",
    "\n",
    "test_x = test['Desc']\n",
    "test_y = test[columns_to_convert+columns_to_convert_2].to_numpy()\n",
    "# test_y_2 = test[columns_to_convert_2].to_numpy()\n",
    "\n",
    "\n",
    "val_x = val['Desc']\n",
    "val_y = val[columns_to_convert+columns_to_convert_2].to_numpy()\n",
    "# val_y_2 = val[columns_to_convert_2].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d6c97f7",
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1696863071912,
     "user": {
      "displayName": "Антон Бабкин",
      "userId": "11833288714987979986"
     },
     "user_tz": -180
    },
    "id": "2d6c97f7"
   },
   "outputs": [],
   "source": [
    "#в статье они на глазок определяли какието токены, я в другом блокноте\n",
    "#такое делал, у меня наверное десять получилось, но можно попробовать дргуое"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b3cd42a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 177,
     "referenced_widgets": [
      "6a4728af925f41a69229f6aac21ae741",
      "7a4c9169b3064b449661a13899a5457c",
      "b4348a557ec641d3be9ed828c7fb5126",
      "d09a5afe8e9244808dbd5a90b0f9a3b9",
      "a9abf24964ae46eebc49b4f9475000dc",
      "eeb2964555df4f56b7b0740d3ba7399a",
      "6411abb7597c47a8a36b5bafe79292e4",
      "70ce9b00e340413c974515410f9fe15e",
      "b8f903032ff34e318f2d41bc3bdfafc6",
      "3a8a35eaeeec4c46ac183f5cd9083861",
      "bcab64dabd294eb883ca523ab2c7312c",
      "a654b16b4304450db39de4b3f9dc56c0",
      "2d85ae221a524408a49c86575c738817",
      "43d8792c398e4164ad2dee9603514577",
      "d83ca6c2c6de4702863da17f98a6337d",
      "5cb6b6744b514c36a6b795017efadfe3",
      "c946c3f5103c482dbe6f2788078829a8",
      "db693d8fa9734c508bb1b6f04169deb5",
      "c419f22082204fafaac6b82384d12ebf",
      "c68138410cac4ec28d71b95d205ccb9d",
      "c8d1e814a6cd4ea19ae1043fa4b30dd6",
      "a5fd7eec008149f48f90bbfd5923d40b",
      "b958f2fca424497fa0b5fdd0e93425b7",
      "efb041e795234859ba1b3b37f2b5a5ad",
      "1f6342661efb46e4bfd839ce09166543",
      "94bf1579c70142a7920a446e805e325d",
      "0208e6cbe4f0485bb213d06fb183bca4",
      "b8c354e1975040599d7341cba24c482c",
      "8fe4c41d60824c81ac455137e6efa6e4",
      "dc3aec24f75b47bc8bc8a3d3b2bae0e2",
      "79cb6f06341046819158d244f9f0e4d8",
      "b4f5c654ffb94f678d53676a220ef57e",
      "b3006e8bad3547728235d17c6e5fef21",
      "0898688d59b74593bf35b6ce0af62dc3",
      "dd5b33e51e304b96b34f7b530243f4c5",
      "86831175b8554cb49911d570b4f18a2a",
      "89221fdeb62d447580dda067a8647a5a",
      "79c0664dba9942d4b49d060767b53554",
      "c9972fd328ad4487a04611d42049b559",
      "12df6dac46c5427db68685fd3980b47d",
      "4b488858e6a74df3894dd2837b86f241",
      "0ec14257cf0542a395125638b22c3e1a",
      "b92b13f075374ce99eca5995ae66ccdf",
      "8a71cb4e6d3a454592cfbbb33bc0bc31",
      "dcbb29cd790f49c4b4234ceb34e21e28",
      "8bb02e3a2fd04c73a1f517dbd51b26e7",
      "96c063c8bf674ad29de6dab03e61a1bb",
      "3672221c1036419b8f9b7e6560cfc286",
      "0993f8ab73924ee28b9e181dbb951edc",
      "61d2f26ca419408dae3288e34b720b49",
      "be99a5a8bbe347179aab9f44bd13cb56",
      "3b3b9b7577064217b8b760a7ddc994d9",
      "46f7303b886e4871b0d07461e5896989",
      "76676012a36747da9c98f6dc4c210e18",
      "9aed13efe3b54716ac30b2224a8984aa"
     ]
    },
    "executionInfo": {
     "elapsed": 30110,
     "status": "ok",
     "timestamp": 1696863102013,
     "user": {
      "displayName": "Антон Бабкин",
      "userId": "11833288714987979986"
     },
     "user_tz": -180
    },
    "id": "9b3cd42a",
    "outputId": "adff4c05-2e24-4942-8f4b-875d7cdd9d1b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"DeepPavlov/rubert-base-cased-sentence\")\n",
    "bert = AutoModel.from_pretrained(\"DeepPavlov/rubert-base-cased-sentence\")\n",
    "bert.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b11b617",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nnew_vocabulary = {}\\n\\nfor i in tqdm(range(int(len(df)))):\\n    deb = str(df['Desc'][i]).split()\\n    for j in deb:\\n        if len(tokenizer.encode(j)) > 3:\\n            count = new_vocabulary.get(j, 0)\\n            new_vocabulary.update({j:count+1})\\n\\nnew_vocabulary = (sorted(new_vocabulary.items(), key=lambda item: -item[1]))\\nto_learn = []\\nfor i in new_vocabulary:\\n    if i[1]>5:\\n        to_learn.append(i[0])\\nto_learn = set(to_learn) - set(tokenizer.vocab.keys())\\ntokenizer.add_tokens(list(to_learn))\\nbert.resize_token_embeddings(len(tokenizer))\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "new_vocabulary = {}\n",
    "\n",
    "for i in tqdm(range(int(len(df)))):\n",
    "    deb = str(df['Desc'][i]).split()\n",
    "    for j in deb:\n",
    "        if len(tokenizer.encode(j)) > 3:\n",
    "            count = new_vocabulary.get(j, 0)\n",
    "            new_vocabulary.update({j:count+1})\n",
    "\n",
    "new_vocabulary = (sorted(new_vocabulary.items(), key=lambda item: -item[1]))\n",
    "to_learn = []\n",
    "for i in new_vocabulary:\n",
    "    if i[1]>5:\n",
    "        to_learn.append(i[0])\n",
    "to_learn = set(to_learn) - set(tokenizer.vocab.keys())\n",
    "tokenizer.add_tokens(list(to_learn))\n",
    "bert.resize_token_embeddings(len(tokenizer))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de788821",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "648a8296",
   "metadata": {
    "executionInfo": {
     "elapsed": 11887,
     "status": "ok",
     "timestamp": 1696863113856,
     "user": {
      "displayName": "Антон Бабкин",
      "userId": "11833288714987979986"
     },
     "user_tz": -180
    },
    "id": "648a8296"
   },
   "outputs": [],
   "source": [
    "tokens_train = tokenizer.batch_encode_plus(train_x.astype('str'), max_length=10,\n",
    "                                          padding='max_length', truncation = True)\n",
    "tokens_val = tokenizer.batch_encode_plus(val_x.astype('str'), max_length=10,\n",
    "                                          padding='max_length', truncation = True)\n",
    "tokens_test = tokenizer.batch_encode_plus(test_x.astype('str'), max_length=10,\n",
    "                                          padding='max_length', truncation = True)\n",
    "\n",
    "\n",
    "train_seq = torch.tensor(tokens_train['input_ids'])\n",
    "train_mask = torch.tensor(tokens_train['attention_mask'])\n",
    "train_y = torch.tensor(train_y)\n",
    "# print(train_y)\n",
    "# train_y_2 = torch.tensor(train_y_2)\n",
    "\n",
    "test_seq = torch.tensor(tokens_test['input_ids'])\n",
    "test_mask = torch.tensor(tokens_test['attention_mask'])\n",
    "test_y = torch.tensor(test_y)\n",
    "# test_y_2 = torch.tensor(test_y_2)\n",
    "\n",
    "val_seq = torch.tensor(tokens_val['input_ids'])\n",
    "val_mask = torch.tensor(tokens_val['attention_mask'])\n",
    "val_y = torch.tensor(val_y)\n",
    "# val_y_2 = torch.tensor(val_y_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b860c79",
   "metadata": {
    "executionInfo": {
     "elapsed": 49,
     "status": "ok",
     "timestamp": 1696863113857,
     "user": {
      "displayName": "Антон Бабкин",
      "userId": "11833288714987979986"
     },
     "user_tz": -180
    },
    "id": "3b860c79"
   },
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "\n",
    "train_data = TensorDataset(train_seq, train_mask, train_y)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size = batch_size)\n",
    "\n",
    "val_data = TensorDataset(val_seq, val_mask, val_y)\n",
    "val_sampler = SequentialSampler(val_data)\n",
    "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size = batch_size)\n",
    "\n",
    "test_data = TensorDataset(test_seq, test_mask, test_y)\n",
    "test_sampler = SequentialSampler(test_data)\n",
    "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size = batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be938144",
   "metadata": {},
   "source": [
    "# !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08b89241",
   "metadata": {
    "executionInfo": {
     "elapsed": 39,
     "status": "ok",
     "timestamp": 1696863113858,
     "user": {
      "displayName": "Антон Бабкин",
      "userId": "11833288714987979986"
     },
     "user_tz": -180
    },
    "id": "08b89241"
   },
   "outputs": [],
   "source": [
    "for param in bert.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "\n",
    "    \n",
    "class BERT_Arch(nn.Module):\n",
    "\n",
    "    def __init__(self):#, bert):\n",
    "        super(BERT_Arch, self).__init__()\n",
    "        #self.bert = bert\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc1 = nn.Linear(768,512)\n",
    "        self.fc2 = nn.Linear(512,amount_of_classes)\n",
    "        self.softmax = nn.LogSoftmax(dim = 1)\n",
    "\n",
    "    def forward(self, cls_hs):#, sent_id, mask):\n",
    "        #cls_hs is pooler output in docs\n",
    "       #_, cls_hs = self.bert(sent_id, attention_mask = mask, return_dict = False)\n",
    "        x = self.fc1(cls_hs)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97f396dc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 36,
     "status": "ok",
     "timestamp": 1696863113860,
     "user": {
      "displayName": "Антон Бабкин",
      "userId": "11833288714987979986"
     },
     "user_tz": -180
    },
    "id": "97f396dc",
    "outputId": "9dfb199c-efde-47b1-d66c-19b485fec184"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'..\\\\model\\\\model1.pt'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 30\n",
    "cross_entropy = nn.CrossEntropyLoss()\n",
    "\n",
    "model = BERT_Arch()\n",
    "\n",
    "model = model.to(device)\n",
    "from transformers import AdamW\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr= 1e-3)\n",
    "\n",
    "model_1_path = os.path.join('..', 'model', 'model1.pt')\n",
    "model_1_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b6e4284f",
   "metadata": {
    "executionInfo": {
     "elapsed": 504,
     "status": "ok",
     "timestamp": 1696863114341,
     "user": {
      "displayName": "Антон Бабкин",
      "userId": "11833288714987979986"
     },
     "user_tz": -180
    },
    "id": "b6e4284f"
   },
   "outputs": [],
   "source": [
    "def evaluate():\n",
    "    model.eval()\n",
    "    total_loss, total_accuracy = 0,0\n",
    "    total_preds = []\n",
    "\n",
    "    for step, batch in tqdm(enumerate(val_dataloader), total = len(val_dataloader)):\n",
    "        batch = [t.to(device) for t in batch]\n",
    "        sent_id, mask, labels = batch\n",
    "        \n",
    "        labels = labels[:amount_of_classes]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            _, cls_hs = bert(sent_id, mask, return_dict = False)\n",
    "            preds = model(cls_hs)\n",
    "\n",
    "            labels = torch.argmax(labels, dim=1)\n",
    "\n",
    "            loss = cross_entropy(preds, labels)\n",
    "            total_loss = total_loss + loss.item()\n",
    "            preds = preds.detach().cpu().numpy()\n",
    "            total_preds.append(preds)\n",
    "\n",
    "    avg_loss = total_loss / len(val_dataloader)\n",
    "    total_preds = np.concatenate(total_preds, axis = 0)\n",
    "\n",
    "    return avg_loss, total_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30ed8264",
   "metadata": {
    "executionInfo": {
     "elapsed": 30,
     "status": "ok",
     "timestamp": 1696863114344,
     "user": {
      "displayName": "Антон Бабкин",
      "userId": "11833288714987979986"
     },
     "user_tz": -180
    },
    "id": "30ed8264"
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    total_loss, total_accuracy = 0, 0\n",
    "    total_preds = []\n",
    "\n",
    "    for step, batch in tqdm(enumerate(train_dataloader), total = len(train_dataloader)):\n",
    "        batch = [r.to(device) for r   in batch]\n",
    "        sent_id, mask, labels = batch\n",
    "        \n",
    "        labels = labels[:amount_of_classes]\n",
    "        \n",
    "        model.zero_grad()\n",
    "        _, cls_hs = bert(sent_id, mask, return_dict = False)\n",
    "        preds = model(cls_hs)\n",
    "\n",
    "        labels = torch.argmax(labels, dim=1)\n",
    "\n",
    " \n",
    "        loss = cross_entropy(preds, labels)\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        preds = preds.detach().cpu().numpy()\n",
    "        total_preds.append(preds)\n",
    "        \n",
    "\n",
    "    avg_loss = total_loss / len(train_dataloader)\n",
    "    total_preds = np.concatenate(total_preds, axis = 0)\n",
    "\n",
    "    return avg_loss, total_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "46f8c15c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "46f8c15c",
    "outputId": "f968ca9f-49da-4ead-b674-c660342eeb0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch1 / 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3825/3825 [00:51<00:00, 74.49it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1275/1275 [00:14<00:00, 87.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 0.164\n",
      "Validation loss: 0.140\n",
      "\n",
      " Epoch2 / 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3825/3825 [00:48<00:00, 78.07it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1275/1275 [00:14<00:00, 87.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 0.118\n",
      "Validation loss: 0.115\n",
      "\n",
      " Epoch3 / 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3825/3825 [00:49<00:00, 78.00it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1275/1275 [00:14<00:00, 87.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 0.110\n",
      "Validation loss: 0.092\n",
      "\n",
      " Epoch4 / 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3825/3825 [00:48<00:00, 78.07it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1275/1275 [00:14<00:00, 87.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 0.105\n",
      "Validation loss: 0.082\n",
      "\n",
      " Epoch5 / 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3825/3825 [00:48<00:00, 78.28it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1275/1275 [00:14<00:00, 88.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 0.098\n",
      "Validation loss: 0.088\n",
      "\n",
      " Epoch6 / 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3825/3825 [00:48<00:00, 78.34it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1275/1275 [00:14<00:00, 88.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 0.093\n",
      "Validation loss: 0.086\n",
      "\n",
      " Epoch7 / 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3825/3825 [00:48<00:00, 78.33it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1275/1275 [00:14<00:00, 88.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 0.093\n",
      "Validation loss: 0.108\n",
      "\n",
      " Epoch8 / 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3825/3825 [00:48<00:00, 78.21it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1275/1275 [00:14<00:00, 88.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 0.089\n",
      "Validation loss: 0.079\n",
      "\n",
      " Epoch9 / 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3825/3825 [00:48<00:00, 78.07it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1275/1275 [00:14<00:00, 87.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 0.086\n",
      "Validation loss: 0.080\n",
      "\n",
      " Epoch10 / 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3825/3825 [00:49<00:00, 78.02it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1275/1275 [00:14<00:00, 87.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 0.083\n",
      "Validation loss: 0.095\n",
      "\n",
      " Epoch11 / 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3825/3825 [00:49<00:00, 78.05it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1275/1275 [00:14<00:00, 87.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 0.081\n",
      "Validation loss: 0.080\n",
      "\n",
      " Epoch12 / 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3825/3825 [00:49<00:00, 78.00it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1275/1275 [00:14<00:00, 87.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 0.080\n",
      "Validation loss: 0.110\n",
      "\n",
      " Epoch13 / 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|████████████████████████████████████████████████▌                             | 2383/3825 [00:30<00:18, 77.39it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m Epoch\u001b[39m\u001b[38;5;132;01m{:}\u001b[39;00m\u001b[38;5;124m / \u001b[39m\u001b[38;5;132;01m{:}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(epoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, epochs))\n\u001b[1;32m----> 9\u001b[0m     train_loss, _ \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m     valid_loss, _ \u001b[38;5;241m=\u001b[39m evaluate()\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m valid_loss \u001b[38;5;241m<\u001b[39m best_valid_loss:\n",
      "Cell \u001b[1;32mIn[13], line 13\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m labels \u001b[38;5;241m=\u001b[39m labels[:amount_of_classes]\n\u001b[0;32m     12\u001b[0m model\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 13\u001b[0m _, cls_hs \u001b[38;5;241m=\u001b[39m \u001b[43mbert\u001b[49m\u001b[43m(\u001b[49m\u001b[43msent_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m preds \u001b[38;5;241m=\u001b[39m model(cls_hs)\n\u001b[0;32m     16\u001b[0m labels \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(labels, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1022\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1013\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m   1015\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[0;32m   1016\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m   1017\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1020\u001b[0m     past_key_values_length\u001b[38;5;241m=\u001b[39mpast_key_values_length,\n\u001b[0;32m   1021\u001b[0m )\n\u001b[1;32m-> 1022\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1023\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1024\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1025\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1026\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1027\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1028\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1029\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1030\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1031\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1032\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1033\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1034\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1035\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:612\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    603\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mcheckpoint\u001b[38;5;241m.\u001b[39mcheckpoint(\n\u001b[0;32m    604\u001b[0m         create_custom_forward(layer_module),\n\u001b[0;32m    605\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    609\u001b[0m         encoder_attention_mask,\n\u001b[0;32m    610\u001b[0m     )\n\u001b[0;32m    611\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 612\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    613\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    614\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    615\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    616\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    617\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    618\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    619\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    620\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    622\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    623\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:497\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    485\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m    486\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    487\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    494\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[0;32m    495\u001b[0m     \u001b[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[0;32m    496\u001b[0m     self_attn_past_key_value \u001b[38;5;241m=\u001b[39m past_key_value[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 497\u001b[0m     self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mself_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    504\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    506\u001b[0m     \u001b[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:427\u001b[0m, in \u001b[0;36mBertAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    417\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m    418\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    419\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    425\u001b[0m     output_attentions: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    426\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m--> 427\u001b[0m     self_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    428\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    429\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    430\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    431\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    432\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    433\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    434\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    435\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    436\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(self_outputs[\u001b[38;5;241m0\u001b[39m], hidden_states)\n\u001b[0;32m    437\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (attention_output,) \u001b[38;5;241m+\u001b[39m self_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:286\u001b[0m, in \u001b[0;36mBertSelfAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    276\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m    277\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    278\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    284\u001b[0m     output_attentions: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    285\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m--> 286\u001b[0m     mixed_query_layer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    288\u001b[0m     \u001b[38;5;66;03m# If this is instantiated as a cross-attention module, the keys\u001b[39;00m\n\u001b[0;32m    289\u001b[0m     \u001b[38;5;66;03m# and values come from an encoder; the attention mask needs to be\u001b[39;00m\n\u001b[0;32m    290\u001b[0m     \u001b[38;5;66;03m# such that the encoder's padding tokens are not attended to.\u001b[39;00m\n\u001b[0;32m    291\u001b[0m     is_cross_attention \u001b[38;5;241m=\u001b[39m encoder_hidden_states \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_valid_loss = float('inf')\n",
    "\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print('\\n Epoch{:} / {:}'.format(epoch+1, epochs))\n",
    "\n",
    "    train_loss, _ = train()\n",
    "    valid_loss, _ = evaluate()\n",
    "\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), model_1_path)\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "    print(f'\\nTraining loss: {train_loss:.3f}')\n",
    "    print(f'Validation loss: {valid_loss:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "15119a62",
   "metadata": {
    "id": "15119a62"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.load_state_dict(torch.load(model_1_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "24001802",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1275/1275 [00:14<00:00, 86.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9797999607766229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#my evaluation after training\n",
    "\n",
    "model.eval()\n",
    "model.to(device)\n",
    "count_true = 0\n",
    "count_total = 0\n",
    "for step, batch in tqdm(enumerate(test_dataloader), total = len(test_dataloader)):\n",
    "    batch = [t.to(device) for t in batch]\n",
    "    sent_id, mask, labels = batch\n",
    "    labels= labels[:amount_of_classes]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        _, cls_hs = bert(sent_id, mask, return_dict=False)\n",
    "        preds = model(cls_hs)\n",
    "        preds = torch.argmax(preds, dim=1)\n",
    "        preds = preds.cpu().numpy()\n",
    "        labels = torch.argmax(labels, dim=1)\n",
    "        labels = list((labels).cpu().numpy())\n",
    "#         print(labels==preds, preds, labels)\n",
    "    \n",
    "    for index in range(len(preds)):\n",
    "        count_total += 1\n",
    "        if preds[index] == labels[index]:\n",
    "            count_true += 1\n",
    "            \n",
    "\n",
    "print(count_true/count_total)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "101d2184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9797999607766229\n"
     ]
    }
   ],
   "source": [
    "print(count_true/count_total)\n",
    "# 3 epochs on group only is 0.97734\n",
    "# 0.921455 on 30 epochs with bert training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "314a5861",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(valid_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf305661",
   "metadata": {},
   "source": [
    "# category classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b20d7803",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in bert.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "class second(nn.Module):\n",
    "\n",
    "    def __init__(self, amount_of_classes, amount_of_classes_2):\n",
    "        super(second, self).__init__()\n",
    "\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc1 = nn.Linear(768 + amount_of_classes ,1024)\n",
    "        self.fc2 = nn.Linear(1024,amount_of_classes_2)\n",
    "        self.softmax = nn.LogSoftmax(dim = 1)\n",
    "\n",
    "    def forward(self, cls_hs, target_1):\n",
    "        #cls_hs is pooler output in docs\n",
    "        #_, cls_hs = self.bert(sent_id, attention_mask = mask, return_dict = False)\n",
    "#         print(cls_hs.shape, target_1.shape)\n",
    "        concated = (torch.cat((cls_hs, target_1), 1))\n",
    "        x = self.fc1(concated)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c162a6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "\n",
    "cross_entropy = nn.CrossEntropyLoss()\n",
    "# cross_entropy = nn.KLDivLoss(reduction=\"batchmean\")\n",
    "\n",
    "model_second = second(amount_of_classes, amount_of_classes_2)\n",
    "\n",
    "model_second = model_second.to(device)\n",
    "from transformers import AdamW\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr= 1e-3)\n",
    "\n",
    "model_2_path = os.path.join('..', 'model', 'model2.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "db72c2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_second():\n",
    "    model_second.eval()\n",
    "    total_loss, total_accuracy = 0,0\n",
    "    total_preds = []\n",
    "\n",
    "    for step, batch in tqdm(enumerate(val_dataloader), total = len(val_dataloader)):\n",
    "        batch = [t.to(device) for t in batch]\n",
    "        sent_id, mask, labels = batch\n",
    "        \n",
    "        #my bad code\n",
    "        labels= list(labels.cpu().numpy())\n",
    "        corr_answ = []\n",
    "        for label in labels:\n",
    "            label = list(label[amount_of_classes:])\n",
    "            corr_answ.append(label.index(1))\n",
    "        corr_answ = torch.tensor(corr_answ).to(device)\n",
    "            \n",
    "\n",
    "        with torch.no_grad():\n",
    "            _, cls_hs = bert(sent_id, attention_mask = mask, return_dict = False)\n",
    "\n",
    "            target_1 = model(cls_hs)\n",
    "            preds = model_second(cls_hs, target_1)\n",
    "\n",
    "            #labels = torch.argmax(labels, dim=1)\n",
    "\n",
    "            loss = cross_entropy(preds, corr_answ)\n",
    "\n",
    "            total_loss = total_loss + loss.item()\n",
    "            preds = preds.detach().cpu().numpy()\n",
    "            total_preds.append(preds)\n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "    avg_loss = total_loss / len(val_dataloader)\n",
    "    total_preds = np.concatenate(total_preds, axis = 0)\n",
    "\n",
    "    return avg_loss, total_preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4d771bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_second():\n",
    "    model_second.train()\n",
    "    total_loss, total_accuracy = 0, 0\n",
    "    total_preds = []\n",
    "\n",
    "    for step, batch in tqdm(enumerate(train_dataloader), total = len(train_dataloader)):\n",
    "        batch = [r.to(device) for r in batch]\n",
    "        sent_id,mask,labels = batch\n",
    "        \n",
    "        labels= list(labels.cpu().numpy())\n",
    "        corr_answ = []\n",
    "        for label in labels:\n",
    "            label = list(label[amount_of_classes:])\n",
    "            corr_answ.append(label.index(1))\n",
    "        corr_answ = torch.tensor(corr_answ).to(device)\n",
    "        \n",
    "#         print('correct answers (indexes):', corr_answ)\n",
    "#         print('labels:', labels)\n",
    "        \n",
    "        model_second.zero_grad()\n",
    "        _, cls_hs = bert(sent_id, attention_mask = mask, return_dict = False)\n",
    "        target_1 = model(cls_hs)\n",
    "        \n",
    "        preds = model_second(cls_hs, target_1)\n",
    "\n",
    "#         for i in range(len(corr_answ)):\n",
    "            \n",
    "        \n",
    "        loss = cross_entropy(preds, corr_answ)\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        preds = preds.detach().cpu().numpy()\n",
    "        total_preds.append(preds)\n",
    "        \n",
    "\n",
    "    avg_loss = total_loss / len(train_dataloader)\n",
    "    total_preds = np.concatenate(total_preds, axis = 0)\n",
    "\n",
    "    return avg_loss, total_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f0pfewS7XtrF",
   "metadata": {
    "id": "f0pfewS7XtrF",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch1 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3825/3825 [00:51<00:00, 73.75it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1275/1275 [00:15<00:00, 84.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving...\n",
      "\n",
      "Training loss: 3.932\n",
      "Validation loss: 3.605\n",
      "\n",
      " Epoch2 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3825/3825 [00:51<00:00, 74.37it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1275/1275 [00:14<00:00, 85.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving...\n",
      "\n",
      "Training loss: 3.559\n",
      "Validation loss: 3.473\n",
      "\n",
      " Epoch3 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3825/3825 [00:51<00:00, 74.57it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1275/1275 [00:14<00:00, 85.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving...\n",
      "\n",
      "Training loss: 3.466\n",
      "Validation loss: 3.376\n",
      "\n",
      " Epoch4 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3825/3825 [00:51<00:00, 74.65it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1275/1275 [00:14<00:00, 86.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving...\n",
      "\n",
      "Training loss: 3.414\n",
      "Validation loss: 3.345\n",
      "\n",
      " Epoch5 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3825/3825 [00:51<00:00, 74.72it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1275/1275 [00:14<00:00, 86.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving...\n",
      "\n",
      "Training loss: 3.380\n",
      "Validation loss: 3.312\n",
      "\n",
      " Epoch6 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3825/3825 [00:51<00:00, 74.77it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1275/1275 [00:14<00:00, 86.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving...\n",
      "\n",
      "Training loss: 3.358\n",
      "Validation loss: 3.295\n",
      "\n",
      " Epoch7 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3825/3825 [00:51<00:00, 74.67it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1275/1275 [00:14<00:00, 86.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving...\n",
      "\n",
      "Training loss: 3.345\n",
      "Validation loss: 3.281\n",
      "\n",
      " Epoch8 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3825/3825 [00:51<00:00, 74.56it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1275/1275 [00:14<00:00, 86.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 3.322\n",
      "Validation loss: 3.284\n",
      "\n",
      " Epoch9 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3825/3825 [00:51<00:00, 74.70it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1275/1275 [00:14<00:00, 86.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 3.309\n",
      "Validation loss: 3.281\n",
      "\n",
      " Epoch10 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3825/3825 [00:51<00:00, 74.66it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1275/1275 [00:14<00:00, 86.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving...\n",
      "\n",
      "Training loss: 3.293\n",
      "Validation loss: 3.228\n",
      "\n",
      " Epoch11 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3825/3825 [00:51<00:00, 74.67it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1275/1275 [00:14<00:00, 86.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 3.288\n",
      "Validation loss: 3.249\n",
      "\n",
      " Epoch12 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3825/3825 [00:51<00:00, 74.60it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1275/1275 [00:14<00:00, 85.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving...\n",
      "\n",
      "Training loss: 3.270\n",
      "Validation loss: 3.195\n",
      "\n",
      " Epoch13 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3825/3825 [00:51<00:00, 74.71it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1275/1275 [00:14<00:00, 86.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving...\n",
      "\n",
      "Training loss: 3.243\n",
      "Validation loss: 3.182\n",
      "\n",
      " Epoch14 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3825/3825 [00:51<00:00, 74.77it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1275/1275 [00:14<00:00, 86.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving...\n",
      "\n",
      "Training loss: 3.225\n",
      "Validation loss: 3.174\n",
      "\n",
      " Epoch15 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3825/3825 [00:51<00:00, 74.75it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1275/1275 [00:14<00:00, 86.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving...\n",
      "\n",
      "Training loss: 3.222\n",
      "Validation loss: 3.167\n",
      "\n",
      " Epoch16 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3825/3825 [00:51<00:00, 74.68it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1275/1275 [00:14<00:00, 86.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 3.210\n",
      "Validation loss: 3.199\n",
      "\n",
      " Epoch17 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3825/3825 [00:51<00:00, 74.63it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1275/1275 [00:14<00:00, 86.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 3.207\n",
      "Validation loss: 3.181\n",
      "\n",
      " Epoch18 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3825/3825 [00:51<00:00, 74.70it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1275/1275 [00:14<00:00, 86.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving...\n",
      "\n",
      "Training loss: 3.202\n",
      "Validation loss: 3.163\n",
      "\n",
      " Epoch19 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3825/3825 [00:51<00:00, 74.72it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1275/1275 [00:14<00:00, 85.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 3.196\n",
      "Validation loss: 3.173\n",
      "\n",
      " Epoch20 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3825/3825 [00:51<00:00, 74.64it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1275/1275 [00:14<00:00, 86.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving...\n",
      "\n",
      "Training loss: 3.197\n",
      "Validation loss: 3.151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "best_valid_loss = float('inf')\n",
    "\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print('\\n Epoch{:} / {:}'.format(epoch+1, epochs))\n",
    "\n",
    "    train_loss, _ = train_second()\n",
    "    valid_loss, _ = evaluate_second()\n",
    "\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        print('saving...')\n",
    "        torch.save(model_second.state_dict(), model_2_path)\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "    print(f'\\nTraining loss: {train_loss:.3f}')\n",
    "    print(f'Validation loss: {valid_loss:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2051b937",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model_second.load_state_dict(torch.load(model_2_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6a40042a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 0/1275 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'te' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 42\u001b[0m\n\u001b[0;32m     40\u001b[0m tmp1, tmp2 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([tmp1]), torch\u001b[38;5;241m.\u001b[39mtensor([tmp2])\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m#print(tokenizer.convert_ids_to_tokens(sent_id[index]))\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mte\u001b[49m)\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28mprint\u001b[39m(encoder_2\u001b[38;5;241m.\u001b[39minverse_transform(tmp1), encoder_2\u001b[38;5;241m.\u001b[39minverse_transform(tmp2))\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m preds[index] \u001b[38;5;241m==\u001b[39m correct:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'te' is not defined"
     ]
    }
   ],
   "source": [
    "#my evaluation after training\n",
    "\n",
    "model_second.eval()\n",
    "model_second.to(device)\n",
    "count_true = 0\n",
    "count_total = 1\n",
    "for step, batch in tqdm(enumerate(test_dataloader), total = len(test_dataloader)):\n",
    "    batch = [t.to(device) for t in batch]\n",
    "    sent_id, mask, labels = batch\n",
    "#     print('eto', len(labels))\n",
    "    #labels= labels[amount_of_classes:amount_of_classes_2]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        _, cls_hs = bert(sent_id, attention_mask = mask, return_dict = False)\n",
    "        target_1 = model(cls_hs)\n",
    "        preds=model_second(cls_hs, target_1)\n",
    "        preds = torch.argmax(preds, dim=1)\n",
    "        preds = preds.cpu().numpy()\n",
    "#         labels = torch.argmax(labels, dim=1)\n",
    "#         labels = list((labels).cpu().numpy())\n",
    "#         print(labels==preds, preds, labels)\n",
    "    \n",
    "    labels = list(labels)\n",
    "#     print(min(preds), preds)\n",
    "    if max(preds >= 98):\n",
    "        print('aaa', preds)\n",
    "        continue\n",
    "    \n",
    "    for index in range(len(preds)):        \n",
    "        correct = list(labels[index][amount_of_classes:].cpu().numpy()).index(1)\n",
    "#         print(correct)\n",
    "#         print(preds[index])\n",
    "        count_total += 1\n",
    "        tmp1 = [0] * amount_of_classes_2\n",
    "#         print(preds)\n",
    "#         tmp1[preds[index]] = 1\n",
    "        \n",
    "        tmp2 = [0] * amount_of_classes_2\n",
    "        tmp2[correct] = 1\n",
    "        tmp1, tmp2 = torch.tensor([tmp1]), torch.tensor([tmp2])\n",
    "        #print(tokenizer.convert_ids_to_tokens(sent_id[index]))\n",
    "        print(te)\n",
    "        print(encoder_2.inverse_transform(tmp1), encoder_2.inverse_transform(tmp2))\n",
    "        if preds[index] == correct:\n",
    "            count_true += 1\n",
    "            \n",
    "\n",
    "print(count_true/count_total)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7213092b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross entropy:\n",
    "# 0.3078 on 30 epochs without training bert and without adding new vocabulary\n",
    "# 0.075203 with new vocab and bert training\n",
    "# 0.41190 without bert training\n",
    "\n",
    "\n",
    "#kld loss:\n",
    "#       without bert training and with vocab\n",
    "# 0.00039  what"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee34bf13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832ee7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "encoders = {'path1': model_1_path, 'path2':model_2_path, 'encoder1': encoder, 'encoder2':encoder_2, \n",
    "            'num_classes1': amount_of_classes, 'num_classes2':amount_of_classes_2}\n",
    "\n",
    "pickle_path = os.path.join('..', 'model', 'encoders.pkl')\n",
    "with open(pickle_path, \"wb\") as f:\n",
    "    pickle.dump(encoders, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedfb968",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(encoders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc121ae0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1803680",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9119f65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49085ba2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
